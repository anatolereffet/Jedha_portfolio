{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34c00c84",
   "metadata": {},
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d4ba60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import  OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) # to avoid deprecation warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6166d056",
   "metadata": {},
   "outputs": [],
   "source": [
    "walmart_df = pd.read_csv('./data/walmart_store_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9e722b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Store             int64\n",
       "Weekly_Sales    float64\n",
       "Holiday_Flag    float64\n",
       "Temperature     float64\n",
       "Fuel_Price      float64\n",
       "CPI             float64\n",
       "Unemployment    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "walmart_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce7855d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "walmart_df['Store'] = walmart_df['Store'].astype(object)\n",
    "walmart_df['Holiday_Flag'] = walmart_df['Holiday_Flag'].astype(object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b4f112",
   "metadata": {},
   "source": [
    "### Separate target variable Y from features X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed9a2609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separating labels from features...\n"
     ]
    }
   ],
   "source": [
    "target_name = 'Weekly_Sales'\n",
    "\n",
    "print(\"Separating labels from features...\")\n",
    "Y = walmart_df.loc[:,target_name]\n",
    "X = walmart_df.loc[:,[c for c in walmart_df.columns if c!=target_name]]\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state =0)\n",
    "\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "Y_train = Y_train.tolist()\n",
    "Y_test = Y_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af421184",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify numerical features = Temperature, Fuel_Price, CPI, Unemployment\n",
    "numeric_features = [2,3,4,5]\n",
    "numerical_transformer = Pipeline(steps = [\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ae8fd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify categorical features = Holiday_Flag, Store\n",
    "categorical_features = [0,1]\n",
    "categorical_transformer = Pipeline(\n",
    "    steps = [\n",
    "        ('imputer_cat', SimpleImputer(strategy = 'most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown = 'ignore'))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050ca6f7",
   "metadata": {},
   "source": [
    "### Pre-processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45f51ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('num', numerical_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e77e02b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Store            object\n",
       "Weekly_Sales    float64\n",
       "Holiday_Flag     object\n",
       "Temperature     float64\n",
       "Fuel_Price      float64\n",
       "CPI             float64\n",
       "Unemployment    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "walmart_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68354384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "[[16 0.0 61.79 2.7110000000000003 189.5231276 6.867999999999999]\n",
      " [5 0.0 69.17 3.594 224.0192873 5.4220000000000015]\n",
      " [19 0.0 33.26 3.789 133.9587419 7.771]\n",
      " [8 0.0 82.92 3.554 219.07019680000005 6.425]\n",
      " [1 0.0 74.78 2.854 210.3374261 7.808]]\n",
      "-------------------------------------\n",
      "  (0, 0)\t0.042603619566292404\n",
      "  (0, 1)\t-1.2684064129831014\n",
      "  (0, 2)\t0.20507787897090277\n",
      "  (0, 3)\t-0.5553454246885398\n",
      "  (0, 18)\t1.0\n",
      "  (0, 23)\t1.0\n",
      "  (1, 0)\t0.45927689938857913\n",
      "  (1, 1)\t0.5805882929947872\n",
      "  (1, 2)\t1.092603852656994\n",
      "  (1, 3)\t-2.1273444147693765\n",
      "  (1, 8)\t1.0\n",
      "  (1, 23)\t1.0\n",
      "  (2, 0)\t-1.5681943036491326\n",
      "  (2, 1)\t0.988916682197153\n",
      "  (2, 2)\t-1.2244967736725922\n",
      "  (2, 3)\t0.4263385919387067\n",
      "  (2, 21)\t1.0\n",
      "  (2, 23)\t1.0\n",
      "  (3, 0)\t1.2355990670791537\n",
      "  (3, 1)\t0.49682862341481476\n",
      "  (3, 2)\t0.9652723930663473\n",
      "  (3, 3)\t-1.0369467750383399\n",
      "  (3, 11)\t1.0\n",
      "  (3, 23)\t1.0\n",
      "  (4, 0)\t0.7760163438063336\n",
      "  (4, 1)\t-0.9689655942347007\n",
      "  (4, 2)\t0.740593446601042\n",
      "  (4, 3)\t0.46656263248710983\n",
      "  (4, 4)\t1.0\n",
      "  (4, 23)\t1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Conduct a pre-process on train set \n",
    "\n",
    "print('Train set')\n",
    "print(X_train[0:5,:])\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "print('-------------------------------------')\n",
    "print(X_train[0:5,:])\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62b6d823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set\n",
      "[[6 0.0 78.89 2.759 212.412888 7.0920000000000005]\n",
      " [7 0.0 38.26 2.725 189.7048215 8.963]\n",
      " [11 0.0 52.77 3.51 223.9170153 6.832999999999998]\n",
      " [10 0.0 57.62 3.882 130.6457931 7.545]\n",
      " [3 0.0 82.7 3.346 225.3068615 6.664]]\n",
      "-------------------------------------\n",
      "  (0, 0)\t1.008066097203298\n",
      "  (0, 1)\t-1.1678948094871355\n",
      "  (0, 2)\t0.7939914584280194\n",
      "  (0, 3)\t-0.3118269089360434\n",
      "  (0, 9)\t1.0\n",
      "  (0, 23)\t1.0\n",
      "  (1, 0)\t-1.2858953335798327\n",
      "  (1, 1)\t-1.2390905286301115\n",
      "  (1, 2)\t0.2097525458588324\n",
      "  (1, 3)\t1.722204979335912\n",
      "  (1, 10)\t1.0\n",
      "  (1, 23)\t1.0\n",
      "  (2, 0)\t-0.4666637224387243\n",
      "  (2, 1)\t0.40469298687684513\n",
      "  (2, 2)\t1.0899725726197316\n",
      "  (2, 3)\t-0.5933951927748682\n",
      "  (2, 14)\t1.0\n",
      "  (2, 23)\t1.0\n",
      "  (3, 0)\t-0.19283372147150377\n",
      "  (3, 1)\t1.1836579139705887\n",
      "  (3, 2)\t-1.30973316331895\n",
      "  (3, 3)\t0.18064580372413577\n",
      "  (3, 13)\t1.0\n",
      "  (3, 23)\t1.0\n",
      "  (4, 0)\t1.2231779123961046\n",
      "  (4, 1)\t0.061278341598959125\n",
      "  (4, 2)\t1.1257308892745825\n",
      "  (4, 3)\t-0.777121215820276\n",
      "  (4, 6)\t1.0\n",
      "  (4, 23)\t1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Conduct a pre-process on test set\n",
    "\n",
    "print('Test set')\n",
    "print(X_test[0:5,:])\n",
    "X_test = preprocessor.transform(X_test)\n",
    "print('-------------------------------------')\n",
    "print(X_test[0:5,:])\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c28979",
   "metadata": {},
   "source": [
    "### Train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d202efdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "...Done.\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "\n",
    "print(\"Training model...\")\n",
    "model.fit(X_train, Y_train) # Training is always done on train set !!\n",
    "print(\"...Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0d051864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9369566144771145"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print scores LinearRegression Test set\n",
    "\n",
    "Y_train_pred = model.predict(X_train)\n",
    "Y_test_pred = model.predict(X_test)\n",
    "score = model.score(X_test, Y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "08923729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04562302530375528\n"
     ]
    }
   ],
   "source": [
    "#Score train test\n",
    "#Compute r2 score difference on linear reg\n",
    "r2_train_lineartrain = r2_score(Y_train, Y_train_pred)\n",
    "r2_train_lineartest = r2_score(Y_test, Y_test_pred)\n",
    "\n",
    "linear_diff = r2_train_lineartrain - r2_train_lineartest\n",
    "\n",
    "print(linear_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cb53addd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Store', -2278.113621522603),\n",
       " ('Holiday_Flag', -75460.94596528573),\n",
       " ('Temperature', 801273.689885493),\n",
       " ('Fuel_Price', 38911.54302437009),\n",
       " ('CPI', -423238.2681601989),\n",
       " ('Unemployment', -161228.4052975872)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Feature Importance\n",
    "\n",
    "feature_importance = list(zip(X.columns.to_list(), model.coef_))\n",
    "display(feature_importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fa505c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are clearly close to an overfit, the value is quite high, lets' try to reduce the overfit "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19756ab",
   "metadata": {},
   "source": [
    "### Overfit solutions\n",
    "Regarding an overfit, as we have a linear regression we can run a regularization:\n",
    "\n",
    "- Ridge\n",
    "- Lasso\n",
    "\n",
    "Lasso works well in the case if we have a high number of features (this isn't the case here) as Lasso shrinks the least important features coefficient to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6a1a127a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter was:Ridge(alpha=0)\n",
      "We have a score on training set at 0.9825795636153728\n",
      "We have a score on testing set at 0.9369387293118862\n",
      "Our best R2 score is 0.8607855025280138\n"
     ]
    }
   ],
   "source": [
    "model_2 = Ridge()\n",
    "#We'll tune in GridSearch to try to get the best possible parameters here in our attempt to reduce overfit...\n",
    "parameters = {'alpha':[0,0.1,0.3,0.5]}\n",
    "gridsearch_param_ridge = GridSearchCV(model_2, param_grid = parameters, cv = 3, verbose = 0)\n",
    "\n",
    "gridsearch_param_ridge.fit(X_train, Y_train)\n",
    "gridsearch_param_ridge.best_params_\n",
    "\n",
    "#Instanciate our estimator to get the score according to documentation \n",
    "opti_ridge = gridsearch_param_ridge.best_estimator_\n",
    "print(f'Best parameter was:{opti_ridge}')\n",
    "print('We have a score on training set at', opti_ridge.score(X_train, Y_train))\n",
    "print('We have a score on testing set at', opti_ridge.score(X_test, Y_test))\n",
    "print('Our best R2 score is', gridsearch_param_ridge.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bebb6528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.045640834303486644\n"
     ]
    }
   ],
   "source": [
    "#Compute r2 score diff on ridge linear reg\n",
    "\n",
    "Y_train_predridge = gridsearch_param_ridge.predict(X_train)\n",
    "r2_score_ridgetrain = r2_score(Y_train, Y_train_predridge)\n",
    "Y_test_predridge = gridsearch_param_ridge.predict(X_test)\n",
    "r2_score_ridgetest = r2_score(Y_test, Y_test_predridge)\n",
    "\n",
    "linear_diff_ridge = r2_score_ridgetrain - r2_score_ridgetest\n",
    "print(linear_diff_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "54dc4e31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter was:Lasso(alpha=100)\n",
      "We have a score on training set at 0.9815642539679015\n",
      "We have a score on testing set at 0.9400147979244405\n",
      "Our best R2 score is 0.8631428547350799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/reffet/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:598: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/reffet/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 166031717079.20038, tolerance: 2414569505.5422163\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/reffet/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:598: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/reffet/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 206584913585.11688, tolerance: 2229171922.9554987\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/reffet/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:598: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/reffet/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 129476259691.7595, tolerance: 2153026593.3522453\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/reffet/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:598: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/reffet/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 140681444334.2275, tolerance: 2208126434.785556\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/reffet/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 141303491502.09555, tolerance: 2414569505.5422163\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/reffet/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 134079847503.05948, tolerance: 2229171922.9554987\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/reffet/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 107749650779.90955, tolerance: 2153026593.3522453\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/reffet/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 99699963628.77348, tolerance: 2208126434.785556\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/reffet/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 49981988889.268555, tolerance: 2229171922.9554987\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/reffet/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 77394607392.01912, tolerance: 2153026593.3522453\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/reffet/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 32768605726.25836, tolerance: 2208126434.785556\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/reffet/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 88008651960.73425, tolerance: 2414569505.5422163\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/reffet/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 32460769600.804047, tolerance: 2153026593.3522453\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/reffet/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 56481878595.082794, tolerance: 2208126434.785556\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/reffet/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 64014954062.81964, tolerance: 3009808860.5723906\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "#Same architecture \n",
    "model_3 = Lasso()\n",
    "\n",
    "parameters = {'alpha':[0,50,100,150,300]}\n",
    "gridsearch_param_lasso = GridSearchCV(model_3, param_grid=parameters, cv=4, verbose=0)\n",
    "\n",
    "gridsearch_param_lasso.fit(X_train, Y_train)\n",
    "\n",
    "gridsearch_param_lasso.best_params_\n",
    "\n",
    "opti_lasso = gridsearch_param_lasso.best_estimator_\n",
    "\n",
    "print(f'Best parameter was:{opti_lasso}')\n",
    "print('We have a score on training set at', opti_lasso.score(X_train, Y_train))\n",
    "print('We have a score on testing set at', opti_lasso.score(X_test, Y_test))\n",
    "print('Our best R2 score is', gridsearch_param_lasso.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cb5743af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04154945604346094\n"
     ]
    }
   ],
   "source": [
    "#Compute r2 score diff on lasso linear reg\n",
    "Y_train_predlasso = gridsearch_param_lasso.predict(X_train)\n",
    "r2_score_lassotrain = r2_score(Y_train, Y_train_predlasso)\n",
    "Y_test_predlasso = gridsearch_param_lasso.predict(X_test)\n",
    "r2_score_lassotest = r2_score(Y_test, Y_test_predlasso)\n",
    "\n",
    "linear_diff_lasso = r2_score_lassotrain - r2_score_lassotest\n",
    "print(linear_diff_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5eb67fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear difference 0.04562302530375528\n",
      "Ridge difference 0.045640834303486644\n",
      "Lasso difference 0.04154945604346094\n"
     ]
    }
   ],
   "source": [
    "print('Linear difference', linear_diff)\n",
    "print('Ridge difference', linear_diff_ridge)\n",
    "print('Lasso difference', linear_diff_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55611cbe",
   "metadata": {},
   "source": [
    "### Conclusion \n",
    "\n",
    "- Lasso seems to be working better here in comparison to Ridge, it's a slight improvement 0.0035\n",
    "- We could try to get more features with the date maybe ? \n",
    "- We might need more data here to assess our problem 90 rows might not be enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5018029",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
